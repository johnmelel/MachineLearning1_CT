{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal Notes\n",
    "\n",
    "On macbook pro\n",
    "- Using arm64 architecture is faster than x86_64 for pyspark jobs: `arch -arm64 /bin/zsh`\n",
    "  - Verify: `uname -m`\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "def start_spark():\n",
    "    spark = (SparkSession.builder\n",
    "             .master(\"local[*]\") # use all cores on computer/dynamically adjust based of cpu count and maximize parallism forcomput vector opertations\n",
    "             .appName(\"Clinical_Notes_Processing\")\n",
    "             .config(\"spark.driver.memory\", \"8g\") # half of ram on mac\n",
    "             .config(\"spark.executor.memory\", \"4g\")\n",
    "             .config(\"spark.driver.maxResultSize\", \"2g\") # increase for embeddings rapidly growing\n",
    "             .config(\"spark.sql.shuffle.partitions\", \"8\")\n",
    "             .config(\"spark.executor.cores\", \"4\")\n",
    "             .config(\"spark.driver.extraJavaOptions\", \"-XX:+UseG1GC\") # more efficient garbage collector. Helpful for large heaps containing embedded vectors \n",
    "             .getOrCreate())\n",
    "\n",
    "    # Reduce shuffle partitions\n",
    "    spark.conf.set(\"spark.sql.shuffle.partitions\", \"50\")\n",
    "\n",
    "    print(\"Spark Version:\", spark.version)\n",
    "    print(\"Spark UI: http://localhost:4040\")\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_resources(spark):\n",
    "    spark.stop()\n",
    "    return start_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version: 3.5.4\n",
      "Spark UI: http://localhost:4040\n"
     ]
    }
   ],
   "source": [
    "spark = start_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Drive is mounted successfully!\n",
      "Files in Drive: ['(ReferHere)Final_Dataset_Data_Folder ', 'merged_5000_patient_radio.csv', 'mimic-iv-ext-clinical-decision-making-a-mimic-iv-derived-dataset-for-evaluation-of-large-language-models-on-the-task-of-clinical-decision-making-for-abdominal-pathologies-1.1.zip', '.DS_Store', 'extracted_zip', 'Project_Presentation.pptx', 'JM outputs', 'SQL DB Export', 'mimiciv.db', 'mimic-iv-3.1.zip', 'Machine Learning I Team 5 Project Proposal.gdoc', 'YY_codes', 'mimic-iv-note-deidentified-free-text-clinical-notes-2.2.zip', 'merged_5000_patient.csv', 'Project Idea.gdoc', 'Final_Dataset_Data_Folder_unzip', 'MLI_2025_Winter', 'Sagana Outputs', 'merged_5000_patient_radio_disc.csv', 'Project Milestone-I.gdoc', 'Dataset Readme.gdoc']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "GOOGLE_DRIVE_LOCAL_MOUNT='/Users/sagana/Library/CloudStorage/GoogleDrive-sondande@uchicago.edu/.shortcut-targets-by-id/1O2pwlZERv3B7ki78Wn0brrpnArRBTFdH/MLI_2025 Winter/'\n",
    "\n",
    "# Check if Google Drive is accessible\n",
    "if os.path.exists(GOOGLE_DRIVE_LOCAL_MOUNT):\n",
    "    print(\"Google Drive is mounted successfully!\")\n",
    "    print(\"Files in Drive:\", os.listdir(GOOGLE_DRIVE_LOCAL_MOUNT))\n",
    "else:\n",
    "    print(\"Google Drive is not mounted. Please check your installation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+\n",
      "|           table|              schema|\n",
      "+----------------+--------------------+\n",
      "|   diagnoses_icd|['subject_id', 'h...|\n",
      "|       discharge|['subject_id', 'h...|\n",
      "|        drgcodes|['subject_id', 'h...|\n",
      "| d_icd_diagnoses|['icd_code', 'icd...|\n",
      "|d_icd_procedures|['icd_code', 'icd...|\n",
      "+----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import collect_set, collect_list, struct, col, when, count, countDistinct, lit\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Read in schema file and process to get schemas needed\n",
    "schemas_df = spark.read.csv(f'{GOOGLE_DRIVE_LOCAL_MOUNT}/SQL DB Export/CSV/schema.csv', header=True)\n",
    "schemas_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------------------+--------------------------------------------------------------------------------+\n",
      "|subject_id| hadm_id|          charttime|                                                                            text|\n",
      "+----------+--------+-------------------+--------------------------------------------------------------------------------+\n",
      "|  10000117|    NULL|2175-05-10 10:12:00|BILATERAL DIGITAL SCREENING MAMMOGRAM WITH CAD\\\\n\\\\nHISTORY:  Baseline screen...|\n",
      "|  10000117|    NULL|2177-05-23 13:18:00|INDICATION:  ___ female with right epigastric pain radiating to back,\\\\nrule ...|\n",
      "|  10000117|    NULL|2178-08-29 13:39:00|CLINICAL HISTORY:  Right upper quadrant pain, evaluate for gallstones.\\\\n\\\\nA...|\n",
      "|  10000117|22927623|2181-11-15 00:40:00|EXAMINATION:   CHEST (PA AND LAT)\\\\n\\\\nINDICATION:  History: ___ with PMH GER...|\n",
      "|  10000117|22927623|2181-11-15 00:47:00|EXAMINATION:   NECK SOFT TISSUES\\\\n\\\\nINDICATION:  ___ woman with dysphasia. ...|\n",
      "|  10000117|    NULL|2182-05-21 16:39:00|EXAMINATION:  LIVER OR GALLBLADDER US (SINGLE ORGAN)\\\\n\\\\nINDICATION:  ___ wi...|\n",
      "|  10000117|    NULL|2182-12-22 08:13:00|EXAMINATION:  LIVER OR GALLBLADDER US (SINGLE ORGAN)\\\\n\\\\nINDICATION:  ___ ye...|\n",
      "|  10000117|    NULL|2183-07-24 13:57:00|EXAMINATION:  CT HEAD W/O CONTRAST Q111 CT HEAD\\\\n\\\\nINDICATION:  ___ year ol...|\n",
      "|  10000117|27988844|2183-09-18 09:48:00|EXAMINATION:  Left hip radiographs, two views, and pelvis radiograph, single\\...|\n",
      "|  10000117|27988844|2183-09-18 12:29:00|EXAMINATION:  Chest radiographs, PA and lateral.\\\\n\\\\nINDICATION:  Preoperati...|\n",
      "|  10000117|27988844|2183-09-19 09:38:00|EXAMINATION:  HIP NAILING IN OR W/FILMS AND FLUORO LEFT\\\\n\\\\nINDICATION:  LEF...|\n",
      "|  10000117|    NULL|2183-10-03 08:26:00|INDICATION:  ___ year old woman with L hip fx// assess fx\\\\n\\\\nCOMPARISON:  R...|\n",
      "|  10000117|    NULL|2183-11-15 10:19:00|EXAMINATION:  HIP UNILAT MIN 2 VIEWS LEFT\\\\n\\\\nINDICATION:  ___ year old woma...|\n",
      "|  10000117|    NULL|2184-01-10 09:32:00|EXAMINATION:  HIP UNILAT MIN 2 VIEWS LEFT\\\\n\\\\nINDICATION:  ___ year old woma...|\n",
      "|  10000117|    NULL|2184-04-17 09:52:00|EXAMINATION:  HIP UNILAT MIN 2 VIEWS IN O.R. LEFT\\\\n\\\\nINDICATION:  ___ year ...|\n",
      "|  10000117|    NULL|2184-08-11 08:28:00|EXAMINATION:  HIP UNILAT MIN 2 VIEWS LEFT\\\\n\\\\nINDICATION:  ___ year old woma...|\n",
      "|  10000117|    NULL|2174-08-14 17:29:00|CHEST RADIOGRAPH PERFORMED.\\\\n\\\\nCOMPARISON:  None.\\\\n\\\\nCLINICAL HISTORY:  _...|\n",
      "|  10000117|    NULL|2175-05-10 10:13:00|INDICATION:  ___ female with dysfunctional uterine bleeding.\\\\n\\\\nNo prior ex...|\n",
      "|  10000248|    NULL|2192-11-29 20:50:00|EXAMINATION:  CT OF THE ABDOMEN AND PELVIS\\\\n\\\\nINDICATION:  Expanding right ...|\n",
      "|  10000560|    NULL|2189-06-26 14:01:00|INDICATION:  ___ woman with lower abdominal pain, constant _____,\\\\nevaluate ...|\n",
      "+----------+--------+-------------------+--------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct schema\n",
    "radiology_schema_list = ast.literal_eval(schemas_df.filter(col(\"table\") == 'radiology').select(col(\"schema\")).collect()[0][0])\n",
    "radiology_schema = StructType([\n",
    "    StructField(x, StringType(), True) for x in radiology_schema_list\n",
    "])\n",
    "\n",
    "# Read in radiology dataset\n",
    "radiology_df = spark.read.option(\"delimiter\", \"|\").option(\"quote\", '\"').option(\"multiLine\", \"true\").csv(f'{GOOGLE_DRIVE_LOCAL_MOUNT}/Sagana Outputs/Clinical Notes Creation/Input Data/radiology.csv', schema=radiology_schema)\n",
    "radiology_df.show(truncate= 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------------------+--------------------------------------------------------------------------------+\n",
      "|subject_id| hadm_id|          charttime|                                                                            text|\n",
      "+----------+--------+-------------------+--------------------------------------------------------------------------------+\n",
      "|  10000117|27988844|2183-09-21 00:00:00| \\\\nName:  ___                 Unit No:   ___\\\\n \\\\nAdmission Date:  ___     ...|\n",
      "|  10000117|22927623|2181-11-15 00:00:00| \\\\nName:  ___                 Unit No:   ___\\\\n \\\\nAdmission Date:  ___     ...|\n",
      "|  10000248|20600184|2192-11-30 00:00:00| \\\\nName:  ___                      Unit No:   ___\\\\n \\\\nAdmission Date:  ___...|\n",
      "|  10000560|28979390|2189-10-17 00:00:00| \\\\nName:  ___                     Unit No:   ___\\\\n \\\\nAdmission Date:  ___ ...|\n",
      "|  10000764|27897940|2132-10-19 00:00:00| \\\\nName:  ___               Unit No:   ___\\\\n \\\\nAdmission Date:  ___       ...|\n",
      "|  10000826|28289260|2147-01-02 00:00:00| \\\\nName:  ___.          Unit No:   ___\\\\n \\\\nAdmission Date:  ___           ...|\n",
      "|  10000826|21086876|2146-12-24 00:00:00| \\\\nName:  ___.          Unit No:   ___\\\\n \\\\nAdmission Date:  ___           ...|\n",
      "|  10000826|20032235|2146-12-12 00:00:00| \\\\nName:  ___.          Unit No:   ___\\\\n \\\\nAdmission Date:  ___           ...|\n",
      "|  10011449|27619916|2135-12-01 00:00:00| \\\\nName:  ___                 Unit No:   ___\\\\n \\\\nAdmission Date:  ___     ...|\n",
      "|  10016367|23401924|2137-12-12 00:00:00| \\\\nName:  ___                    Unit No:   ___\\\\n \\\\nAdmission Date:  ___  ...|\n",
      "|  10016367|23401924|2137-12-12 00:00:00| \\\\nName:  ___                    Unit No:   ___\\\\n \\\\nAdmission Date:  ___  ...|\n",
      "|  10016367|26107656|2135-04-02 00:00:00| \\\\nName:  ___                    Unit No:   ___\\\\n \\\\nAdmission Date:  ___  ...|\n",
      "|  10016367|26107656|2135-04-02 00:00:00| \\\\nName:  ___                    Unit No:   ___\\\\n \\\\nAdmission Date:  ___  ...|\n",
      "|  10016367|20343876|2129-03-31 00:00:00| \\\\nName:  ___                    Unit No:   ___\\\\n \\\\nAdmission Date:  ___  ...|\n",
      "|  10016367|20343876|2129-03-31 00:00:00| \\\\nName:  ___                    Unit No:   ___\\\\n \\\\nAdmission Date:  ___  ...|\n",
      "|  10016367|27955224|2129-02-18 00:00:00| \\\\nName:  ___                    Unit No:   ___\\\\n \\\\nAdmission Date:  ___  ...|\n",
      "|  10016367|27955224|2129-02-18 00:00:00| \\\\nName:  ___                    Unit No:   ___\\\\n \\\\nAdmission Date:  ___  ...|\n",
      "|  10029484|20764029|2160-11-11 00:00:00| \\\\nName:  ___                Unit No:   ___\\\\n \\\\nAdmission Date:  ___      ...|\n",
      "|  10054496|25245648|2124-12-11 00:00:00| \\\\nName:  ___              Unit No:   ___\\\\n \\\\nAdmission Date:  ___        ...|\n",
      "|  10054496|25035451|2120-05-03 00:00:00| \\\\nName:  ___              Unit No:   ___\\\\n \\\\nAdmission Date:  ___        ...|\n",
      "+----------+--------+-------------------+--------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read in radiology dataset\n",
    "discharge_schema_list = ast.literal_eval(schemas_df.filter(col(\"table\") == 'discharge').select(col(\"schema\")).collect()[0][0])\n",
    "discharge_schema = StructType([\n",
    "    StructField(x, StringType(), True) for x in discharge_schema_list\n",
    "])\n",
    "\n",
    "discharge_df = spark.read.option(\"delimiter\", \"|\").option(\"quote\", '\"').option(\"multiLine\", \"true\").csv(f'{GOOGLE_DRIVE_LOCAL_MOUNT}/Sagana Outputs/Clinical Notes Creation/Input Data/discharge.csv', schema=discharge_schema)\n",
    "discharge_df.show(truncate= 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only required fields\n",
    "radiology_df_filtered = radiology_df.select('subject_id', 'text')\n",
    "discharge_df_filtered = discharge_df.select('subject_id', 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+----------+-----------+---------+--------+--------------+-----+-----------------------+------------------------+----+------+------+----+\n",
      "|subject_id|gender|anchor_age|anchor_year|insurance|language|marital_status| race|blood_pressure_systolic|blood_pressure_diastolic| bmi|height|weight|egfr|\n",
      "+----------+------+----------+-----------+---------+--------+--------------+-----+-----------------------+------------------------+----+------+------+----+\n",
      "|  10000117|     F|        48|       2174| Medicaid| English|      DIVORCED|WHITE|                    108|                      74|18.9|    64|   110|NULL|\n",
      "|  10000161|     M|        60|       2163| Medicaid| English|        SINGLE|WHITE|                    106|                      92|NULL|  NULL|  NULL|NULL|\n",
      "|  10000248|     M|        34|       2192|  Private| English|       MARRIED|WHITE|                   NULL|                    NULL|25.5|    68|   168|NULL|\n",
      "|  10000280|     M|        20|       2151|  Private| English|          NULL|OTHER|                    125|                      77|NULL|  NULL| 170.5|NULL|\n",
      "|  10000560|     F|        53|       2189|  Private| English|       MARRIED|WHITE|                    124|                      78|NULL|  NULL|   128|NULL|\n",
      "+----------+------+----------+-----------+---------+--------+--------------+-----+-----------------------+------------------------+----+------+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter for only notes where we have a patient to ensure we filter down datasets\n",
    "patients_df = spark.read.csv(f'{GOOGLE_DRIVE_LOCAL_MOUNT}/JM outputs/patients_cleaned.csv', header=True)\n",
    "patients_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_radiology_df = radiology_df_filtered.join(patients_df, radiology_df_filtered.subject_id == patients_df.subject_id, 'left_semi')\n",
    "final_radiology_df_updated = final_radiology_df.withColumnRenamed('text', 'radiology_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_discharge_df = discharge_df_filtered.join(patients_df, discharge_df_filtered.subject_id == patients_df.subject_id, 'left_semi')\n",
    "final_discharge_df_updated = final_discharge_df.withColumnRenamed('text', 'discharge_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 38:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+\n",
      "|subject_id|      radiology_text|      discharge_text|\n",
      "+----------+--------------------+--------------------+\n",
      "|  10001663|Addendum:\\\\n\\\\nAd...| \\\\nName:  ___   ...|\n",
      "+----------+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "combined_df = final_radiology_df_updated.join(final_discharge_df_updated, how='inner', on=['subject_id'])\n",
    "combined_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4650350"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the dataset for sample set for embeddings\n",
    "# Sample without replacement to have a dataset that is representative of the original dataset\n",
    "# Add seed for reproducibility\n",
    "\n",
    "# Ensure sampling contains same subject_ids in both datasets\n",
    "combined_df_sample = combined_df.sample(False, 0.002, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9235"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_sample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 64:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+\n",
      "|subject_id|      radiology_text|      discharge_text|\n",
      "+----------+--------------------+--------------------+\n",
      "|  10023708|INDICATION:  Preo...| \\\\nName:  ___   ...|\n",
      "|  10023708|HISTORY:  Screeni...| \\\\nName:  ___   ...|\n",
      "|  10023708|EXAMINATION:  WRI...| \\\\nName:  ___   ...|\n",
      "|  10071302|INDICATION:  ___ ...| \\\\nName:  ___   ...|\n",
      "|  10076263|HISTORY:  ___ fem...| \\\\nName:  ___   ...|\n",
      "|  10076263|EXAMINATION:  DX ...| \\\\nName:  ___   ...|\n",
      "|  10076263|INDICATION:  ___ ...| \\\\nName:  ___   ...|\n",
      "|  10076263|EXAMINATION:  CT ...| \\\\nName:  ___   ...|\n",
      "|  10076263|INDICATION:  ___ ...| \\\\nName:  ___   ...|\n",
      "|  10076263|EXAMINATION:  UNI...| \\\\nName:  ___   ...|\n",
      "|  10076263|EXAMINATION:  DX ...| \\\\nName:  ___   ...|\n",
      "|  10076263|EXAMINATION:  DX ...| \\\\nName:  ___   ...|\n",
      "|  10076263|INDICATION:  ___ ...| \\\\nName:  ___   ...|\n",
      "|  10076263|INDICATION:  ___ ...| \\\\nName:  ___   ...|\n",
      "|  10102822|INDICATION:  ___ ...| \\\\nName:  ___   ...|\n",
      "|  10104436|EXAMINATION:  Rad...| \\\\nName:  ___   ...|\n",
      "|  10104549|INDICATION:  Shor...| \\\\nName:  ___   ...|\n",
      "|  10108132|INDICATION:  ___ ...| \\\\nName:  ___   ...|\n",
      "|  10118315|REASON FOR EXAMIN...| \\\\nName:  ___   ...|\n",
      "|  10118315|HISTORY:  Broncho...| \\\\nName:  ___   ...|\n",
      "+----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "combined_df_sample.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df_sample.write.mode(\"overwrite\").option(\"compression\", \"snappy\").parquet('combined_cn_sample/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- subject_id: string (nullable = true)\n",
      " |-- radiology_text: string (nullable = true)\n",
      " |-- discharge_text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_df_sample.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_radiology_df_count  = final_radiology_df.count()\n",
    "# distinct_radiology_df_count = final_radiology_df.select('subject_id').distinct().count()\n",
    "# final_discharge_df_count = final_discharge_df.count()\n",
    "# distinct_discharge_df_count = final_discharge_df.select('subject_id').distinct().count()\n",
    "\n",
    "# sampled_rad_count = sampled_final_radiology_df.count()\n",
    "# distinct_rad_count = sampled_final_radiology_df.select('subject_id').distinct().count()\n",
    "# sampled_dis_count = sampled_final_discharge_df.count()\n",
    "# distinct_dis_count = sampled_final_discharge_df.select('subject_id').distinct().count()\n",
    "\n",
    "# print(f\"Original Radiology Count: {final_radiology_df_count}, Distinct Radiology Count: {distinct_radiology_df_count}\")\n",
    "# print(f\"Sampled Radiology Count: {sampled_rad_count}, Distinct Radiology Count: {distinct_rad_count}\")\n",
    "# print(f\"Original Discharge Count: {final_discharge_df_count}, Distinct Discharge Count: {distinct_discharge_df_count}\")\n",
    "# print(f\"Sampled Discharge Count: {sampled_dis_count}, Distinct Discharge Count: {distinct_dis_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Suppose \"sampled_df\" has a vector column \"embeddings\"\n",
    "# # 1. Convert Spark vector to array, then collect\n",
    "# from pyspark.sql.functions import udf\n",
    "# from pyspark.ml.linalg import VectorUDT\n",
    "# import numpy as np\n",
    "\n",
    "# # Convert Spark Vector to Python list\n",
    "# def to_array(v):\n",
    "#     return v.toArray().tolist()\n",
    "\n",
    "# to_array_udf = udf(to_array, \"array<double>\")\n",
    "# sampled_df_array = sampled_df.withColumn(\"embeddings_array\", to_array_udf(\"embeddings\"))\n",
    "\n",
    "# # 2. Collect to Pandas\n",
    "# pdf = sampled_df_array.select(\"embeddings_array\").limit(5000).toPandas()  # limit for memory safety\n",
    "# X = np.array(pdf[\"embeddings_array\"].tolist())  # shape: (n_samples, embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_radiology_df.write.mode(\"overwrite\").option(\"compression\", \"snappy\").parquet('radiology_filtered/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_discharge_df.write.mode(\"overwrite\").option(\"compression\", \"snappy\").parquet('discharge_filtered/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Processed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discharge_processed_df = spark.read.parquet('discharge_processed/')\n",
    "# radio_processed_df = spark.read.parquet('radiology_processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import expr\n",
    "# from pyspark.sql.functions import to_json, cola\n",
    "\n",
    "# df = discharge_processed_df.withColumn(\"sections\", to_json(col(\"sections\")))  # Convert map column to JSON string\n",
    "# df = df.withColumn(\"entities\", to_json(col(\"entities\")))\n",
    "# # df.write.csv(\"output_directory\", header=True, mode=\"overwrite\")\n",
    "# # df.coalesce(1).write.csv(\"discharge_processed_csv/\", header=True, mode=\"overwrite\")\n",
    "# df_PD = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_PD.to_csv('discharge_processed_csv/discharge_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import expr\n",
    "# from pyspark.sql.functions import to_json, col\n",
    "\n",
    "# df = radio_processed_df.withColumn(\"sections\", to_json(col(\"sections\")))  # Convert map column to JSON string\n",
    "# df = df.withColumn(\"entities\", to_json(col(\"entities\")))\n",
    "# # df.write.csv(\"output_directory\", header=True, mode=\"overwrite\")\n",
    "# # df.coalesce(1).write.csv(\"discharge_processed_csv/\", header=True, mode=\"overwrite\")\n",
    "# df_PD = df.toPandas()\n",
    "# df_PD.to_csv('radiology_processed_csv/radio_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_PD.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review embeddings output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark = start_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_dis = spark.read.parquet('discharge_text/clinical_notes_sampled_embedded/')\n",
    "embedded_radio = spark.read.parquet('radiology_text/clinical_notes_sampled_embedded/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+---------------------------+------------------------+\n",
      "|subject_id|      discharge_text|cleaned_discharge_text_text|embedding_discharge_text|\n",
      "+----------+--------------------+---------------------------+------------------------+\n",
      "|  10004296| \\\\nName:  ___   ...|       name: ___ unit no...|    [0.07342699, 0.06...|\n",
      "|  10007058| \\\\nName:  ___   ...|       name: ___ unit no...|    [0.3247316, -0.22...|\n",
      "|  10031575| \\\\nName:  ___   ...|       name: ___ unit no...|    [0.11593194, -0.0...|\n",
      "|  10031575| \\\\nName:  ___   ...|       name: ___ unit no...|    [0.062262576, 0.0...|\n",
      "|  10036821| \\\\nName:  ___   ...|       name: ___ unit no...|    [0.2427187, -0.10...|\n",
      "|  10036821| \\\\nName:  ___   ...|       name: ___ unit no...|    [0.1506541, -0.00...|\n",
      "|  10048105| \\\\nName:  ___   ...|       name: ___ unit no...|    [0.17518048, -0.4...|\n",
      "|  10076617| \\\\nName:  ___.  ...|       name: ___. unit n...|    [0.13433282, -0.1...|\n",
      "|  10076617| \\\\nName:  ___.  ...|       name: ___. unit n...|    [0.13433282, -0.1...|\n",
      "|  10076617| \\\\nName:  ___.  ...|       name: ___. unit n...|    [0.19654866, -0.0...|\n",
      "|  10076617| \\\\nName:  ___.  ...|       name: ___. unit n...|    [0.095946826, -0....|\n",
      "|  10076617| \\\\nName:  ___.  ...|       name: ___. unit n...|    [0.13433282, -0.1...|\n",
      "|  10076617| \\\\nName:  ___.  ...|       name: ___. unit n...|    [0.13433282, -0.1...|\n",
      "|  10076617| \\\\nName:  ___.  ...|       name: ___. unit n...|    [0.21126863, -0.1...|\n",
      "|  10076617| \\\\nName:  ___.  ...|       name: ___. unit n...|    [0.30446616, -0.1...|\n",
      "|  10076617| \\\\nName:  ___.  ...|       name: ___. unit n...|    [0.095946826, -0....|\n",
      "|  10097612| \\\\nName:  ___   ...|       name: ___ unit no...|    [0.11732407, -0.0...|\n",
      "|  10098008| \\\\nName:  ___   ...|       name: ___ unit no...|    [0.14401351, -0.0...|\n",
      "|  10104308| \\\\nName:  ___   ...|       name: ___ unit no...|    [0.101533726, -0....|\n",
      "|  10104308| \\\\nName:  ___   ...|       name: ___ unit no...|    [0.24791585, -9.8...|\n",
      "+----------+--------------------+---------------------------+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embedded_dis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+---------------------------+------------------------+\n",
      "|subject_id|      radiology_text|cleaned_radiology_text_text|embedding_radiology_text|\n",
      "+----------+--------------------+---------------------------+------------------------+\n",
      "|  10004296|EXAMINATION:  PEL...|       examination: pelv...|    [0.042560313, 0.1...|\n",
      "|  10007058|EXAMINATION:  CTA...|       examination: cta ...|    [0.3039025, -0.13...|\n",
      "|  10031575|EXAMINATION:  CT ...|       examination: ct h...|    [0.12216909, -0.1...|\n",
      "|  10031575|EXAMINATION:  UNI...|       examination: unil...|    [0.10871682, 0.08...|\n",
      "|  10036821|EXAMINATION:  SEC...|       examination: seco...|    [0.33056372, -0.1...|\n",
      "|  10036821|EXAMINATION:  CT ...|       examination: ct c...|    [0.30515096, -0.1...|\n",
      "|  10048105|CHEST RADIOGRAPH\\...|       chest radiograph ...|    [0.19040951, -0.1...|\n",
      "|  10076617|INDICATION:  ___ ...|       indication: ___ w...|    [0.3708051, -0.10...|\n",
      "|  10076617|CHEST RADIOGRAPH\\...|       chest radiograph ...|    [0.21020418, -0.0...|\n",
      "|  10076617|INDICATION:  Rece...|       indication: recen...|    [0.33477488, -0.2...|\n",
      "|  10076617|HISTORY:  Endomet...|       history: endometr...|    [0.2709465, -0.12...|\n",
      "|  10076617|HISTORY:  Postop ...|       history: postop d...|    [0.2003085, 0.087...|\n",
      "|  10076617|EXAMINATION:  CTA...|       examination: cta ...|    [0.2786099, -0.07...|\n",
      "|  10076617|EXAMINATION:  MR ...|       examination: mr h...|    [0.11083328, -0.1...|\n",
      "|  10076617|EXAMINATION:  MR ...|       examination: mr h...|    [0.14980105, -0.1...|\n",
      "|  10076617|EXAMINATION:  US ...|       examination: us m...|    [-0.009295981, -0...|\n",
      "|  10097612|EXAMINATION:  CHE...|       examination: ches...|    [0.1604135, -0.32...|\n",
      "|  10098008|EXAMINATION:  CT ...|       examination: ct a...|    [0.26555514, -0.1...|\n",
      "|  10104308|EXAMINATION:  VEN...|       examination: veno...|    [0.16000837, 0.11...|\n",
      "|  10104308|HISTORY:  ___ man...|       history: ___ man ...|    [0.3314065, -0.08...|\n",
      "+----------+--------------------+---------------------------+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embedded_radio.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_radio_emb = embedded_radio.select('subject_id', 'embedding_radiology_text')\n",
    "filtered_dis_emb = embedded_dis.select('subject_id', 'embedding_discharge_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- subject_id: string (nullable = true)\n",
      " |-- embedding_radiology_text: array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_radio_emb.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_radio_agg = (\n",
    "    filtered_radio_emb\n",
    "    .groupBy(\"subject_id\")\n",
    "    .agg(\n",
    "        collect_set(\"icd_code\").alias(\"proc_codes\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------------+------------------------+\n",
      "|subject_id|embedding_radiology_text|embedding_discharge_text|\n",
      "+----------+------------------------+------------------------+\n",
      "|  10023486|    [0.21450946, -0.1...|    [0.073009044, -0....|\n",
      "|  10023708|    [0.22877766, -0.1...|    [0.13038772, -0.0...|\n",
      "|  10023708|    [0.22877766, -0.1...|    [0.14673024, -0.1...|\n",
      "|  10023708|    [0.14008474, 0.02...|    [0.13038772, -0.0...|\n",
      "|  10023708|    [0.14008474, 0.02...|    [0.14673024, -0.1...|\n",
      "|  10063368|    [0.18466042, -0.1...|    [0.2575382, 0.030...|\n",
      "|  10065615|    [0.05487843, -0.2...|    [0.19949329, -0.4...|\n",
      "|  10065615|    [0.05487843, -0.2...|    [0.19949329, -0.4...|\n",
      "|  10065615|    [0.30068773, -0.2...|    [0.19949329, -0.4...|\n",
      "|  10065615|    [0.30068773, -0.2...|    [0.19949329, -0.4...|\n",
      "|  10066489|    [0.30751058, -0.2...|    [0.124997, -0.092...|\n",
      "|  10076263|    [0.23147626, -0.0...|    [0.27583912, -0.1...|\n",
      "|  10076263|    [0.23147626, -0.0...|    [0.28715703, -0.0...|\n",
      "|  10076263|    [0.23147626, -0.0...|    [0.18400799, -0.3...|\n",
      "|  10076263|    [0.23147626, -0.0...|    [0.13463767, -0.0...|\n",
      "|  10076263|    [0.23147626, -0.0...|    [0.18400799, -0.3...|\n",
      "|  10076263|    [0.23147626, -0.0...|    [0.19354486, -0.0...|\n",
      "|  10076263|    [0.23147626, -0.0...|    [0.28715703, -0.0...|\n",
      "|  10076263|    [0.23147626, -0.0...|    [0.13463767, -0.0...|\n",
      "|  10076263|    [0.23147626, -0.0...|    [0.18400799, -0.3...|\n",
      "+----------+------------------------+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clinical_notes_combined_em = filtered_radio_emb.join(filtered_dis_emb, how='inner', on=['subject_id'])\n",
    "clinical_notes_combined_em.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "568278"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_notes_combined_em.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_notes_PD = clinical_notes_combined_em.toPandas()\n",
    "# c_notes_PD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_notes_PD.to_csv('embedded_clinical_notes_combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_notes_PD.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
