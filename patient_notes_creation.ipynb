{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient Notes Creation and Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "def start_spark():\n",
    "    spark = (SparkSession.builder \n",
    "        .appName(\"NLP-Pipeline\") \n",
    "        .master(\"local[*]\")  # Use all 10 cores; you could also try local[9] to reserve one core\n",
    "        .config(\"spark.driver.memory\", \"8g\") \n",
    "        .config(\"spark.executor.memory\", \"6g\") \n",
    "        .config(\"spark.executor.cores\", \"4\")  # Adjust executor cores to a reasonable number per executor\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"40\")  # Increase partitions to match more cores\n",
    "        .config(\"spark.local.dir\", \"/Users/sagana/spark_temp/\") \n",
    "        .config(\"spark.driver.extraJavaOptions\", \"-XX:+UseG1GC\")\n",
    "        .getOrCreate())\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = start_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Drive is mounted successfully!\n",
      "Files in Drive: ['Project Report.gdoc', '(ReferHere)Final_Dataset_Data_Folder ', 'merged_5000_patient_radio.csv', 'mimic-iv-ext-clinical-decision-making-a-mimic-iv-derived-dataset-for-evaluation-of-large-language-models-on-the-task-of-clinical-decision-making-for-abdominal-pathologies-1.1.zip', '.DS_Store', '2025307-Datasets To Use', 'extracted_zip', 'Clinical Trial_Sample1.docx', 'Project_Presentation.pptx', 'JM outputs', 'SQL DB Export', 'mimiciv.db', 'mimic-iv-3.1.zip', 'Machine Learning I Team 5 Project Proposal.gdoc', 'YY_codes', 'mimic-iv-note-deidentified-free-text-clinical-notes-2.2.zip', 'Junquan_output', 'merged_5000_patient.csv', 'Project Idea.gdoc', 'Final_Dataset_Data_Folder_unzip', 'MLI_2025_Winter', 'Sagana Outputs', 'merged_5000_patient_radio_disc.csv', 'Project Milestone-I.gdoc', 'Dataset Readme.gdoc']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "GOOGLE_DRIVE_LOCAL_MOUNT='/Users/sagana/Library/CloudStorage/GoogleDrive-sondande@uchicago.edu/.shortcut-targets-by-id/1O2pwlZERv3B7ki78Wn0brrpnArRBTFdH/MLI_2025 Winter/'\n",
    "\n",
    "# Check if Google Drive is accessible\n",
    "if os.path.exists(GOOGLE_DRIVE_LOCAL_MOUNT):\n",
    "    print(\"Google Drive is mounted successfully!\")\n",
    "    print(\"Files in Drive:\", os.listdir(GOOGLE_DRIVE_LOCAL_MOUNT))\n",
    "else:\n",
    "    print(\"Google Drive is not mounted. Please check your installation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Notes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+\n",
      "|           table|              schema|\n",
      "+----------------+--------------------+\n",
      "|   diagnoses_icd|['subject_id', 'h...|\n",
      "|       discharge|['subject_id', 'h...|\n",
      "|        drgcodes|['subject_id', 'h...|\n",
      "| d_icd_diagnoses|['icd_code', 'icd...|\n",
      "|d_icd_procedures|['icd_code', 'icd...|\n",
      "|            emar|['subject_id', 'h...|\n",
      "|     hcpcsevents|['subject_id', 'h...|\n",
      "|        patients|['subject_id', 'g...|\n",
      "|        pharmacy|['subject_id', 'h...|\n",
      "|   prescriptions|['subject_id', 'h...|\n",
      "|  procedures_icd|['subject_id', 'h...|\n",
      "|       radiology|['subject_id', 'h...|\n",
      "|        services|['subject_id', 'h...|\n",
      "|patients_cleaned|['subject_id', 'g...|\n",
      "+----------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import collect_set, collect_list, struct, col, when, count, countDistinct, lit\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Read in schema file and process to get schemas needed\n",
    "schemas_df = spark.read.csv('data/schema.csv', header=True)\n",
    "schemas_df.show(30, truncate=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------------------+--------------------------------------------------------------------------------+\n",
      "|subject_id| hadm_id|          charttime|                                                                            text|\n",
      "+----------+--------+-------------------+--------------------------------------------------------------------------------+\n",
      "|  10000117|    NULL|2175-05-10 10:12:00|BILATERAL DIGITAL SCREENING MAMMOGRAM WITH CAD\\\\n\\\\nHISTORY:  Baseline screen...|\n",
      "|  10000117|    NULL|2177-05-23 13:18:00|INDICATION:  ___ female with right epigastric pain radiating to back,\\\\nrule ...|\n",
      "|  10000117|    NULL|2178-08-29 13:39:00|CLINICAL HISTORY:  Right upper quadrant pain, evaluate for gallstones.\\\\n\\\\nA...|\n",
      "|  10000117|22927623|2181-11-15 00:40:00|EXAMINATION:   CHEST (PA AND LAT)\\\\n\\\\nINDICATION:  History: ___ with PMH GER...|\n",
      "|  10000117|22927623|2181-11-15 00:47:00|EXAMINATION:   NECK SOFT TISSUES\\\\n\\\\nINDICATION:  ___ woman with dysphasia. ...|\n",
      "|  10000117|    NULL|2182-05-21 16:39:00|EXAMINATION:  LIVER OR GALLBLADDER US (SINGLE ORGAN)\\\\n\\\\nINDICATION:  ___ wi...|\n",
      "|  10000117|    NULL|2182-12-22 08:13:00|EXAMINATION:  LIVER OR GALLBLADDER US (SINGLE ORGAN)\\\\n\\\\nINDICATION:  ___ ye...|\n",
      "|  10000117|    NULL|2183-07-24 13:57:00|EXAMINATION:  CT HEAD W/O CONTRAST Q111 CT HEAD\\\\n\\\\nINDICATION:  ___ year ol...|\n",
      "|  10000117|27988844|2183-09-18 09:48:00|EXAMINATION:  Left hip radiographs, two views, and pelvis radiograph, single\\...|\n",
      "|  10000117|27988844|2183-09-18 12:29:00|EXAMINATION:  Chest radiographs, PA and lateral.\\\\n\\\\nINDICATION:  Preoperati...|\n",
      "|  10000117|27988844|2183-09-19 09:38:00|EXAMINATION:  HIP NAILING IN OR W/FILMS AND FLUORO LEFT\\\\n\\\\nINDICATION:  LEF...|\n",
      "|  10000117|    NULL|2183-10-03 08:26:00|INDICATION:  ___ year old woman with L hip fx// assess fx\\\\n\\\\nCOMPARISON:  R...|\n",
      "|  10000117|    NULL|2183-11-15 10:19:00|EXAMINATION:  HIP UNILAT MIN 2 VIEWS LEFT\\\\n\\\\nINDICATION:  ___ year old woma...|\n",
      "|  10000117|    NULL|2184-01-10 09:32:00|EXAMINATION:  HIP UNILAT MIN 2 VIEWS LEFT\\\\n\\\\nINDICATION:  ___ year old woma...|\n",
      "|  10000117|    NULL|2184-04-17 09:52:00|EXAMINATION:  HIP UNILAT MIN 2 VIEWS IN O.R. LEFT\\\\n\\\\nINDICATION:  ___ year ...|\n",
      "|  10000117|    NULL|2184-08-11 08:28:00|EXAMINATION:  HIP UNILAT MIN 2 VIEWS LEFT\\\\n\\\\nINDICATION:  ___ year old woma...|\n",
      "|  10000117|    NULL|2174-08-14 17:29:00|CHEST RADIOGRAPH PERFORMED.\\\\n\\\\nCOMPARISON:  None.\\\\n\\\\nCLINICAL HISTORY:  _...|\n",
      "|  10000117|    NULL|2175-05-10 10:13:00|INDICATION:  ___ female with dysfunctional uterine bleeding.\\\\n\\\\nNo prior ex...|\n",
      "|  10000248|    NULL|2192-11-29 20:50:00|EXAMINATION:  CT OF THE ABDOMEN AND PELVIS\\\\n\\\\nINDICATION:  Expanding right ...|\n",
      "|  10000560|    NULL|2189-06-26 14:01:00|INDICATION:  ___ woman with lower abdominal pain, constant _____,\\\\nevaluate ...|\n",
      "+----------+--------+-------------------+--------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct schema\n",
    "radiology_schema_list = ast.literal_eval(schemas_df.filter(col(\"table\") == 'radiology').select(col(\"schema\")).collect()[0][0])\n",
    "radiology_schema = StructType([\n",
    "    StructField(x, StringType(), True) for x in radiology_schema_list\n",
    "])\n",
    "\n",
    "# Read in radiology dataset\n",
    "radiology_df = spark.read.option(\"delimiter\", \"|\").option(\"quote\", '\"').option(\"multiLine\", \"true\").csv(f'{GOOGLE_DRIVE_LOCAL_MOUNT}/Sagana Outputs/Clinical Notes Creation/Input Data/radiology.csv', schema=radiology_schema)\n",
    "radiology_df.show(truncate= 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+---------+----+\n",
      "|subject_id|hadm_id|charttime|text|\n",
      "+----------+-------+---------+----+\n",
      "+----------+-------+---------+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "radiology_null_rows = radiology_df.filter(col(\"charttime\").isNull())\n",
    "radiology_null_rows.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19153"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_patients = spark.read.csv('data/gold_patients.csv', header=True)\n",
    "gold_patients.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.                 (0 + 1) / 1]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# extract the latest radiology note for each patient and text and ensure they are all distinct\u001b[39;00m\n\u001b[1;32m     10\u001b[0m latest_records \u001b[38;5;241m=\u001b[39m radiology_df_filtered\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mra\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mjoin(latest_times\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlt\u001b[39m\u001b[38;5;124m'\u001b[39m), (col(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mra.subject_id\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m col(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlt.subject_id\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     11\u001b[0m                                      (col(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mra.charttime\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m col(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlt.latest_charttime\u001b[39m\u001b[38;5;124m'\u001b[39m)))\u001b[38;5;241m.\u001b[39mselect(col(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mra.subject_id\u001b[39m\u001b[38;5;124m'\u001b[39m), col(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mra.text\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mdistinct()\n\u001b[0;32m---> 13\u001b[0m \u001b[43mlatest_records\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pyspark/sql/dataframe.py:947\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, truncate: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, vertical: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    888\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001b[39;00m\n\u001b[1;32m    889\u001b[0m \n\u001b[1;32m    890\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;124;03m    name | Bob\u001b[39;00m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pyspark/sql/dataframe.py:965\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m    960\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    961\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m    962\u001b[0m     )\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[0;32m--> 965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    967\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socket.py:708\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    710\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "radiology_df_filtered = radiology_df.join(gold_patients, on='subject_id')\n",
    "\n",
    "# label time stammp\n",
    "radiology_df_filtered = radiology_df_filtered.withColumn(\"charttime\", col(\"charttime\").cast(\"timestamp\"))\n",
    "\n",
    "# find the most recent record for each subject_id\n",
    "latest_times = radiology_df_filtered.groupBy(\"subject_id\").agg(F.max(\"charttime\").alias(\"latest_charttime\"))\n",
    "\n",
    "# extract the latest radiology note for each patient and text and ensure they are all distinct\n",
    "latest_records = radiology_df_filtered.alias('ra').join(latest_times.alias('lt'), (col('ra.subject_id') == col('lt.subject_id')) & \n",
    "                                     (col('ra.charttime') == col('lt.latest_charttime'))).select(col('ra.subject_id'), col('ra.text')).distinct()\n",
    "\n",
    "latest_records.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions: 10\n"
     ]
    }
   ],
   "source": [
    "num_partitions = latest_records.rdd.getNumPartitions()\n",
    "print(f\"Number of partitions: {num_partitions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size in bytes: 32106\n",
      "Partition size in bytes: 3210.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "size_in_bytes = latest_records.rdd.mapPartitions(lambda iterator: [sum(len(x) for x in iterator)]).sum()\n",
    "print(f\"Size in bytes: {size_in_bytes}\")\n",
    "partition_size_bytes = size_in_bytes / num_partitions\n",
    "print(f\"Partition size in bytes: {partition_size_bytes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 125:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size in bytes: 32106\n",
      "Partition size in bytes: 32106.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "latest_records = latest_records.coalesce(1)\n",
    "num_partitions = latest_records.rdd.getNumPartitions()\n",
    "size_in_bytes = latest_records.rdd.mapPartitions(lambda iterator: [sum(len(x) for x in iterator)]).sum()\n",
    "print(f\"Size in bytes: {size_in_bytes}\")\n",
    "partition_size_bytes = size_in_bytes / num_partitions\n",
    "print(f\"Partition size in bytes: {partition_size_bytes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_records.toPandas().to_csv('data/radiology_filtered_gold_latest_record.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discharge Notes Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------------------+--------------------------------------------------------------------------------+\n",
      "|subject_id| hadm_id|          charttime|                                                                            text|\n",
      "+----------+--------+-------------------+--------------------------------------------------------------------------------+\n",
      "|  10000117|27988844|2183-09-21 00:00:00| \\\\nName:  ___                 Unit No:   ___\\\\n \\\\nAdmission Date:  ___     ...|\n",
      "|  10000117|22927623|2181-11-15 00:00:00| \\\\nName:  ___                 Unit No:   ___\\\\n \\\\nAdmission Date:  ___     ...|\n",
      "|  10000248|20600184|2192-11-30 00:00:00| \\\\nName:  ___                      Unit No:   ___\\\\n \\\\nAdmission Date:  ___...|\n",
      "|  10000560|28979390|2189-10-17 00:00:00| \\\\nName:  ___                     Unit No:   ___\\\\n \\\\nAdmission Date:  ___ ...|\n",
      "|  10000764|27897940|2132-10-19 00:00:00| \\\\nName:  ___               Unit No:   ___\\\\n \\\\nAdmission Date:  ___       ...|\n",
      "|  10000826|28289260|2147-01-02 00:00:00| \\\\nName:  ___.          Unit No:   ___\\\\n \\\\nAdmission Date:  ___           ...|\n",
      "|  10000826|21086876|2146-12-24 00:00:00| \\\\nName:  ___.          Unit No:   ___\\\\n \\\\nAdmission Date:  ___           ...|\n",
      "|  10000826|20032235|2146-12-12 00:00:00| \\\\nName:  ___.          Unit No:   ___\\\\n \\\\nAdmission Date:  ___           ...|\n",
      "|  10011449|27619916|2135-12-01 00:00:00| \\\\nName:  ___                 Unit No:   ___\\\\n \\\\nAdmission Date:  ___     ...|\n",
      "|  10016367|23401924|2137-12-12 00:00:00| \\\\nName:  ___                    Unit No:   ___\\\\n \\\\nAdmission Date:  ___  ...|\n",
      "|  10016367|23401924|2137-12-12 00:00:00| \\\\nName:  ___                    Unit No:   ___\\\\n \\\\nAdmission Date:  ___  ...|\n",
      "|  10016367|26107656|2135-04-02 00:00:00| \\\\nName:  ___                    Unit No:   ___\\\\n \\\\nAdmission Date:  ___  ...|\n",
      "|  10016367|26107656|2135-04-02 00:00:00| \\\\nName:  ___                    Unit No:   ___\\\\n \\\\nAdmission Date:  ___  ...|\n",
      "|  10016367|20343876|2129-03-31 00:00:00| \\\\nName:  ___                    Unit No:   ___\\\\n \\\\nAdmission Date:  ___  ...|\n",
      "|  10016367|20343876|2129-03-31 00:00:00| \\\\nName:  ___                    Unit No:   ___\\\\n \\\\nAdmission Date:  ___  ...|\n",
      "|  10016367|27955224|2129-02-18 00:00:00| \\\\nName:  ___                    Unit No:   ___\\\\n \\\\nAdmission Date:  ___  ...|\n",
      "|  10016367|27955224|2129-02-18 00:00:00| \\\\nName:  ___                    Unit No:   ___\\\\n \\\\nAdmission Date:  ___  ...|\n",
      "|  10029484|20764029|2160-11-11 00:00:00| \\\\nName:  ___                Unit No:   ___\\\\n \\\\nAdmission Date:  ___      ...|\n",
      "|  10054496|25245648|2124-12-11 00:00:00| \\\\nName:  ___              Unit No:   ___\\\\n \\\\nAdmission Date:  ___        ...|\n",
      "|  10054496|25035451|2120-05-03 00:00:00| \\\\nName:  ___              Unit No:   ___\\\\n \\\\nAdmission Date:  ___        ...|\n",
      "+----------+--------+-------------------+--------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read in radiology dataset\n",
    "discharge_schema_list = ast.literal_eval(schemas_df.filter(col(\"table\") == 'discharge').select(col(\"schema\")).collect()[0][0])\n",
    "discharge_schema = StructType([\n",
    "    StructField(x, StringType(), True) for x in discharge_schema_list\n",
    "])\n",
    "\n",
    "discharge_df = spark.read.option(\"delimiter\", \"|\").option(\"quote\", '\"').option(\"multiLine\", \"true\").csv(f'{GOOGLE_DRIVE_LOCAL_MOUNT}/Sagana Outputs/Clinical Notes Creation/Input Data/discharge.csv', schema=discharge_schema)\n",
    "discharge_df.show(truncate= 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 147:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|subject_id|                text|\n",
      "+----------+--------------------+\n",
      "|  17294481| \\\\nName:  ___   ...|\n",
      "|  18797135| \\\\nName:  ___   ...|\n",
      "|  12318550| \\\\nName:  ___   ...|\n",
      "|  13132088| \\\\nName:  ___   ...|\n",
      "|  14607492| \\\\nName:  ___   ...|\n",
      "|  10599039| \\\\nName:  ___   ...|\n",
      "|  17476573| \\\\nName:  ___   ...|\n",
      "|  18574721| \\\\nName:  ___   ...|\n",
      "|  19951664| \\\\nName:  ___   ...|\n",
      "|  17002262| \\\\nName:  ___   ...|\n",
      "|  15653269| \\\\nName:  ___   ...|\n",
      "|  10021704| \\\\nName:  ___   ...|\n",
      "|  18836076| \\\\nName:  ___   ...|\n",
      "|  14787680| \\\\nName:  ___   ...|\n",
      "|  11420248| \\\\nName:  ___   ...|\n",
      "|  18413065| \\\\nName:  ___   ...|\n",
      "|  18060267| \\\\nName:  ___   ...|\n",
      "|  18523038| \\\\nName:  ___   ...|\n",
      "|  13258618| \\\\nName:  ___   ...|\n",
      "|  15343626| \\\\nName:  ___   ...|\n",
      "+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "discharge_df_filtered = discharge_df.join(gold_patients, on='subject_id')\n",
    "\n",
    "# label time stammp\n",
    "discharge_df_filtered = discharge_df_filtered.withColumn(\"charttime\", col(\"charttime\").cast(\"timestamp\"))\n",
    "\n",
    "# find the most recent record for each subject_id\n",
    "latest_times = discharge_df_filtered.groupBy(\"subject_id\").agg(F.max(\"charttime\").alias(\"latest_charttime\"))\n",
    "\n",
    "# extract the latest radiology note for each patient and text and ensure they are all distinct\n",
    "latest_records = discharge_df_filtered.alias('ds').join(latest_times.alias('lt'), (col('ds.subject_id') == col('lt.subject_id')) & \n",
    "                                     (col('ds.charttime') == col('lt.latest_charttime'))).select(col('ds.subject_id'), col('ds.text')).distinct()\n",
    "\n",
    "latest_records.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_records = latest_records.coalesce(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/10 19:31:01 WARN DiskBlockObjectWriter: Error deleting /Users/sagana/spark_temp/blockmgr-ee9e25d1-69f8-41f2-b8c5-4a63b3343eae/25/temp_shuffle_b5054783-5434-4bc1-b309-9dc24a61e555\n",
      "25/03/10 19:31:01 ERROR TaskContextImpl: Error in TaskCompletionListener\n",
      "org.apache.spark.SparkException: Block broadcast_41 does not exist\n",
      "\tat org.apache.spark.errors.SparkCoreErrors$.blockDoesNotExistError(SparkCoreErrors.scala:318)\n",
      "\tat org.apache.spark.storage.BlockInfoManager.blockInfo(BlockInfoManager.scala:269)\n",
      "\tat org.apache.spark.storage.BlockInfoManager.unlock(BlockInfoManager.scala:390)\n",
      "\tat org.apache.spark.storage.BlockManager.releaseLock(BlockManager.scala:1309)\n",
      "\tat org.apache.spark.broadcast.TorrentBroadcast.$anonfun$releaseBlockManagerLock$1(TorrentBroadcast.scala:319)\n",
      "\tat org.apache.spark.broadcast.TorrentBroadcast.$anonfun$releaseBlockManagerLock$1$adapted(TorrentBroadcast.scala:319)\n",
      "\tat org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:137)\n",
      "\tat org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1(TaskContextImpl.scala:144)\n",
      "\tat org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1$adapted(TaskContextImpl.scala:144)\n",
      "\tat org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:199)\n",
      "\tat org.apache.spark.TaskContextImpl.invokeTaskCompletionListeners(TaskContextImpl.scala:144)\n",
      "\tat org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:137)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:177)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "25/03/10 19:31:01 ERROR TaskContextImpl: Error in TaskCompletionListener\n",
      "org.apache.spark.SparkException: Block broadcast_42 does not exist\n",
      "\tat org.apache.spark.errors.SparkCoreErrors$.blockDoesNotExistError(SparkCoreErrors.scala:318)\n",
      "\tat org.apache.spark.storage.BlockInfoManager.blockInfo(BlockInfoManager.scala:269)\n",
      "\tat org.apache.spark.storage.BlockInfoManager.unlock(BlockInfoManager.scala:390)\n",
      "\tat org.apache.spark.storage.BlockManager.releaseLock(BlockManager.scala:1309)\n",
      "\tat org.apache.spark.broadcast.TorrentBroadcast.$anonfun$releaseBlockManagerLock$1(TorrentBroadcast.scala:319)\n",
      "\tat org.apache.spark.broadcast.TorrentBroadcast.$anonfun$releaseBlockManagerLock$1$adapted(TorrentBroadcast.scala:319)\n",
      "\tat org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:137)\n",
      "\tat org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1(TaskContextImpl.scala:144)\n",
      "\tat org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1$adapted(TaskContextImpl.scala:144)\n",
      "\tat org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:199)\n",
      "\tat org.apache.spark.TaskContextImpl.invokeTaskCompletionListeners(TaskContextImpl.scala:144)\n",
      "\tat org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:137)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:177)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "25/03/10 19:31:01 ERROR Executor: Exception in task 0.0 in stage 39.0 (TID 71): /Users/sagana/spark_temp/blockmgr-ee9e25d1-69f8-41f2-b8c5-4a63b3343eae/25/temp_shuffle_b5054783-5434-4bc1-b309-9dc24a61e555 (No such file or directory)\n"
     ]
    }
   ],
   "source": [
    "latest_records.toPandas().to_csv('data/discharge_filtered_gold_latest_record.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14618137</td>\n",
       "      <td>EXAMINATION:  ___ THYROID SCAN\\\\n\\\\nINDICATION...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13299965</td>\n",
       "      <td>EXAMINATION:\\\\nChest:  Frontal and lateral vie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14776642</td>\n",
       "      <td>EXAMINATION:  FOOT AP,LAT AND OBL RIGHT\\\\n\\\\nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17179127</td>\n",
       "      <td>EXAMINATION:  CHEST (PORTABLE AP)\\\\n\\\\nINDICAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13332476</td>\n",
       "      <td>EXAMINATION:  PATELLA (AP, LAT AND SUNRISE) RI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id                                               text\n",
       "0    14618137  EXAMINATION:  ___ THYROID SCAN\\\\n\\\\nINDICATION...\n",
       "1    13299965  EXAMINATION:\\\\nChest:  Frontal and lateral vie...\n",
       "2    14776642  EXAMINATION:  FOOT AP,LAT AND OBL RIGHT\\\\n\\\\nI...\n",
       "3    17179127  EXAMINATION:  CHEST (PORTABLE AP)\\\\n\\\\nINDICAT...\n",
       "4    13332476  EXAMINATION:  PATELLA (AP, LAT AND SUNRISE) RI..."
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rad_df = pd.read_csv('data/radiology_filtered_gold_latest_record.csv')\n",
    "rad_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17294481</td>\n",
       "      <td>\\\\nName:  ___                   Unit No:   __...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18797135</td>\n",
       "      <td>\\\\nName:  ___                 Unit No:   ___\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12318550</td>\n",
       "      <td>\\\\nName:  ___                   Unit No:   __...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13132088</td>\n",
       "      <td>\\\\nName:  ___             Unit No:   ___\\\\n \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14607492</td>\n",
       "      <td>\\\\nName:  ___                     Unit No:   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id                                               text\n",
       "0    17294481   \\\\nName:  ___                   Unit No:   __...\n",
       "1    18797135   \\\\nName:  ___                 Unit No:   ___\\...\n",
       "2    12318550   \\\\nName:  ___                   Unit No:   __...\n",
       "3    13132088   \\\\nName:  ___             Unit No:   ___\\\\n \\...\n",
       "4    14607492   \\\\nName:  ___                     Unit No:   ..."
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis_df = pd.read_csv('discharge_filtered_gold_latest_record.csv')\n",
    "dis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14618137</td>\n",
       "      <td>EXAMINATION:  ___ THYROID SCAN\\\\n\\\\nINDICATION...</td>\n",
       "      <td>examination: ___ thyroid scan ___ year old man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13299965</td>\n",
       "      <td>EXAMINATION:\\\\nChest:  Frontal and lateral vie...</td>\n",
       "      <td>examination: chest: frontal and lateral views ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14776642</td>\n",
       "      <td>EXAMINATION:  FOOT AP,LAT AND OBL RIGHT\\\\n\\\\nI...</td>\n",
       "      <td>examination: foot ap,lat and obl right ___ yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17179127</td>\n",
       "      <td>EXAMINATION:  CHEST (PORTABLE AP)\\\\n\\\\nINDICAT...</td>\n",
       "      <td>examination: chest (portable ap) ___ year old ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13332476</td>\n",
       "      <td>EXAMINATION:  PATELLA (AP, LAT AND SUNRISE) RI...</td>\n",
       "      <td>examination: patella (ap, lat and sunrise) rig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id                                               text  \\\n",
       "0    14618137  EXAMINATION:  ___ THYROID SCAN\\\\n\\\\nINDICATION...   \n",
       "1    13299965  EXAMINATION:\\\\nChest:  Frontal and lateral vie...   \n",
       "2    14776642  EXAMINATION:  FOOT AP,LAT AND OBL RIGHT\\\\n\\\\nI...   \n",
       "3    17179127  EXAMINATION:  CHEST (PORTABLE AP)\\\\n\\\\nINDICAT...   \n",
       "4    13332476  EXAMINATION:  PATELLA (AP, LAT AND SUNRISE) RI...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  examination: ___ thyroid scan ___ year old man...  \n",
       "1  examination: chest: frontal and lateral views ...  \n",
       "2  examination: foot ap,lat and obl right ___ yea...  \n",
       "3  examination: chest (portable ap) ___ year old ...  \n",
       "4  examination: patella (ap, lat and sunrise) rig...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def radiology_cleaning(note):\n",
    "    headers = ['FINDINGS:', 'IMPRESSION:', 'TECHNIQUE:', 'INDICATION:', 'COMPARISON:']\n",
    "    for header in headers:\n",
    "        note = re.sub(r'(?i)' + re.escape(header), '', note)\n",
    "        \n",
    "    note = re.sub(r'\\n+', ' ', note)\n",
    "    note = re.sub(r'[^\\w\\s\\.,;:\\-\\(\\)\\[\\]+]', ' ', note)\n",
    "    note = re.sub(r'\\s+', ' ', note).strip()\n",
    "    \n",
    "    note = note.lower()\n",
    "    return note\n",
    "\n",
    "rad_df['cleaned_text'] = rad_df['text'].apply(radiology_cleaning)\n",
    "rad_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17294481</td>\n",
       "      <td>\\\\nName:  ___                   Unit No:   __...</td>\n",
       "      <td>\\ name: ___ unit no: ___\\ \\ \\ date of birth: _...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18797135</td>\n",
       "      <td>\\\\nName:  ___                 Unit No:   ___\\...</td>\n",
       "      <td>\\ name: ___ unit no: ___\\ \\ \\ date of birth: _...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12318550</td>\n",
       "      <td>\\\\nName:  ___                   Unit No:   __...</td>\n",
       "      <td>\\ name: ___ unit no: ___\\ \\ \\ date of birth: _...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13132088</td>\n",
       "      <td>\\\\nName:  ___             Unit No:   ___\\\\n \\...</td>\n",
       "      <td>\\ name: ___ unit no: ___\\ \\ \\ date of birth: _...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14607492</td>\n",
       "      <td>\\\\nName:  ___                     Unit No:   ...</td>\n",
       "      <td>\\ name: ___ unit no: ___\\ \\ \\ date of birth: _...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id                                               text  \\\n",
       "0    17294481   \\\\nName:  ___                   Unit No:   __...   \n",
       "1    18797135   \\\\nName:  ___                 Unit No:   ___\\...   \n",
       "2    12318550   \\\\nName:  ___                   Unit No:   __...   \n",
       "3    13132088   \\\\nName:  ___             Unit No:   ___\\\\n \\...   \n",
       "4    14607492   \\\\nName:  ___                     Unit No:   ...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  \\ name: ___ unit no: ___\\ \\ \\ date of birth: _...  \n",
       "1  \\ name: ___ unit no: ___\\ \\ \\ date of birth: _...  \n",
       "2  \\ name: ___ unit no: ___\\ \\ \\ date of birth: _...  \n",
       "3  \\ name: ___ unit no: ___\\ \\ \\ date of birth: _...  \n",
       "4  \\ name: ___ unit no: ___\\ \\ \\ date of birth: _...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def discharge_clean(note):\n",
    "    note = re.sub(r'(?im)^(Admission Date:|Discharge Data:|Patient:).*$', '', note)\n",
    "    note = re.sub(r'(?im)Page\\s+\\d+\\s+of\\s+\\d+', '', note)\n",
    "    note = re.sub(r'(?im)^(Signature:|Doctor:|Nurse:).*$', '', note)\n",
    "    note = re.sub(r'\\s+', ' ', note).strip()\n",
    "    \n",
    "    # Remove escape sequences and normalize whitespace.\n",
    "    cleaned = re.sub(r\"\\\\n\", \" \", note)\n",
    "    cleaned = re.sub(r\"\\\\+\", \" \", cleaned)\n",
    "    cleaned = re.sub(r\"\\s+\", \" \", cleaned).strip()\n",
    "    note = note.lower()\n",
    "    return note \n",
    "\n",
    "dis_df['cleaned_text'] = dis_df['text'].apply(discharge_clean)\n",
    "dis_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Radiology Specific Model Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Set device: use MPS on macOS if available; otherwise, use CPU.\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"StanfordAIMI/RadBERT\")\n",
    "model = AutoModel.from_pretrained(\"StanfordAIMI/RadBERT\").to(device)\n",
    "model.eval()\n",
    "if device != \"cpu\":  # Use FP16 only on GPU/MPS devices\n",
    "    model.half()\n",
    "\n",
    "def get_bert_embedding(text):\n",
    "    \"\"\"\n",
    "    Generates an embedding for a single text using RadBERT.\n",
    "    \n",
    "    - Tokenizes the text with a maximum length of 512.\n",
    "    - Uses the CLS token (index 0) from the last hidden state.\n",
    "    - Applies torch.no_grad() for inference speed.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    # Move all tensors to the selected device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Extract the CLS token embedding, convert to FP16 and then to a NumPy array\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().to(torch.float16).cpu().numpy()\n",
    "    return cls_embedding\n",
    "\n",
    "def get_embeddings_for_texts(texts, max_workers=4):\n",
    "    \"\"\"\n",
    "    Processes a list of texts concurrently using ThreadPoolExecutor.\n",
    "    Returns a list of embeddings with a tqdm progress bar.\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(get_bert_embedding, text): idx for idx, text in enumerate(texts)}\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing embeddings\"):\n",
    "            embeddings.append(future.result())\n",
    "    return embeddings\n",
    "\n",
    "def process_dataframe(df, text_column, max_workers=4):\n",
    "    \"\"\"\n",
    "    Applies get_bert_embedding to a Pandas DataFrame column using multi-threading.\n",
    "    Adds a new column 'embeddings' with the computed embeddings.\n",
    "    \"\"\"\n",
    "    texts = df[text_column].tolist()\n",
    "    embeddings = get_embeddings_for_texts(texts, max_workers=max_workers)\n",
    "    df[\"embeddings\"] = embeddings\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Text Embeddings:   0%|          | 0/16053 [08:51<?, ?it/s]\n",
      "Processing embeddings: 100%|| 16053/16053 [06:19<00:00, 42.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14618137</td>\n",
       "      <td>EXAMINATION:  ___ THYROID SCAN\\\\n\\\\nINDICATION...</td>\n",
       "      <td>examination: ___ thyroid scan ___ year old man...</td>\n",
       "      <td>[0.784, -0.2866, 0.5713, 0.0351, 0.10425, -0.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13299965</td>\n",
       "      <td>EXAMINATION:\\\\nChest:  Frontal and lateral vie...</td>\n",
       "      <td>examination: chest: frontal and lateral views ...</td>\n",
       "      <td>[1.279, -0.6196, -0.3943, -0.7603, -0.4463, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14776642</td>\n",
       "      <td>EXAMINATION:  FOOT AP,LAT AND OBL RIGHT\\\\n\\\\nI...</td>\n",
       "      <td>examination: foot ap,lat and obl right ___ yea...</td>\n",
       "      <td>[1.658, -0.6665, 0.4915, 0.721, -0.2544, -0.32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17179127</td>\n",
       "      <td>EXAMINATION:  CHEST (PORTABLE AP)\\\\n\\\\nINDICAT...</td>\n",
       "      <td>examination: chest (portable ap) ___ year old ...</td>\n",
       "      <td>[1.531, -0.2247, 0.3254, 0.6353, -0.1626, 0.52...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13332476</td>\n",
       "      <td>EXAMINATION:  PATELLA (AP, LAT AND SUNRISE) RI...</td>\n",
       "      <td>examination: patella (ap, lat and sunrise) rig...</td>\n",
       "      <td>[0.786, -0.771, -0.1842, -0.01572, 0.6724, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id                                               text  \\\n",
       "0    14618137  EXAMINATION:  ___ THYROID SCAN\\\\n\\\\nINDICATION...   \n",
       "1    13299965  EXAMINATION:\\\\nChest:  Frontal and lateral vie...   \n",
       "2    14776642  EXAMINATION:  FOOT AP,LAT AND OBL RIGHT\\\\n\\\\nI...   \n",
       "3    17179127  EXAMINATION:  CHEST (PORTABLE AP)\\\\n\\\\nINDICAT...   \n",
       "4    13332476  EXAMINATION:  PATELLA (AP, LAT AND SUNRISE) RI...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  examination: ___ thyroid scan ___ year old man...   \n",
       "1  examination: chest: frontal and lateral views ...   \n",
       "2  examination: foot ap,lat and obl right ___ yea...   \n",
       "3  examination: chest (portable ap) ___ year old ...   \n",
       "4  examination: patella (ap, lat and sunrise) rig...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [0.784, -0.2866, 0.5713, 0.0351, 0.10425, -0.7...  \n",
       "1  [1.279, -0.6196, -0.3943, -0.7603, -0.4463, -0...  \n",
       "2  [1.658, -0.6665, 0.4915, 0.721, -0.2544, -0.32...  \n",
       "3  [1.531, -0.2247, 0.3254, 0.6353, -0.1626, 0.52...  \n",
       "4  [0.786, -0.771, -0.1842, -0.01572, 0.6724, -0....  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rad_df = process_dataframe(rad_df, 'cleaned_text', max_workers=4)\n",
    "rad_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16053 entries, 0 to 16052\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   subject_id    16053 non-null  int64 \n",
      " 1   text          16053 non-null  object\n",
      " 2   cleaned_text  16053 non-null  object\n",
      " 3   embeddings    16053 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 501.8+ KB\n"
     ]
    }
   ],
   "source": [
    "rad_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_df.to_csv('data/radiology_with_embeddings.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Discharge Specific Model Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Set device: use MPS on macOS if available; otherwise, use CPU.\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\n",
    "model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\").to(device)\n",
    "model.eval()\n",
    "if device != \"cpu\":  # Use FP16 only on GPU/MPS devices\n",
    "    model.half()\n",
    "\n",
    "def get_bert_embedding(text):\n",
    "    \"\"\"\n",
    "    Generates an embedding for a single text using RadBERT.\n",
    "    \n",
    "    - Tokenizes the text with a maximum length of 512.\n",
    "    - Uses the CLS token (index 0) from the last hidden state.\n",
    "    - Applies torch.no_grad() for inference speed.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    # Move all tensors to the selected device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Extract the CLS token embedding, convert to FP16 and then to a NumPy array\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().to(torch.float16).cpu().numpy()\n",
    "    return cls_embedding\n",
    "\n",
    "def get_embeddings_for_texts(texts, max_workers=4):\n",
    "    \"\"\"\n",
    "    Processes a list of texts concurrently using ThreadPoolExecutor.\n",
    "    Returns a list of embeddings with a tqdm progress bar.\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(get_bert_embedding, text): idx for idx, text in enumerate(texts)}\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing embeddings\"):\n",
    "            embeddings.append(future.result())\n",
    "    return embeddings\n",
    "\n",
    "def process_dataframe(df, text_column, max_workers=4):\n",
    "    \"\"\"\n",
    "    Applies get_bert_embedding to a Pandas DataFrame column using multi-threading.\n",
    "    Adds a new column 'embeddings' with the computed embeddings.\n",
    "    \"\"\"\n",
    "    texts = df[text_column].tolist()\n",
    "    embeddings = get_embeddings_for_texts(texts, max_workers=max_workers)\n",
    "    df[\"embeddings\"] = embeddings\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17294481</td>\n",
       "      <td>\\\\nName:  ___                   Unit No:   __...</td>\n",
       "      <td>\\ name: ___ unit no: ___\\ \\ \\ date of birth: _...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18797135</td>\n",
       "      <td>\\\\nName:  ___                 Unit No:   ___\\...</td>\n",
       "      <td>\\ name: ___ unit no: ___\\ \\ \\ date of birth: _...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12318550</td>\n",
       "      <td>\\\\nName:  ___                   Unit No:   __...</td>\n",
       "      <td>\\ name: ___ unit no: ___\\ \\ \\ date of birth: _...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13132088</td>\n",
       "      <td>\\\\nName:  ___             Unit No:   ___\\\\n \\...</td>\n",
       "      <td>\\ name: ___ unit no: ___\\ \\ \\ date of birth: _...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14607492</td>\n",
       "      <td>\\\\nName:  ___                     Unit No:   ...</td>\n",
       "      <td>\\ name: ___ unit no: ___\\ \\ \\ date of birth: _...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id                                               text  \\\n",
       "0    17294481   \\\\nName:  ___                   Unit No:   __...   \n",
       "1    18797135   \\\\nName:  ___                 Unit No:   ___\\...   \n",
       "2    12318550   \\\\nName:  ___                   Unit No:   __...   \n",
       "3    13132088   \\\\nName:  ___             Unit No:   ___\\\\n \\...   \n",
       "4    14607492   \\\\nName:  ___                     Unit No:   ...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  \\ name: ___ unit no: ___\\ \\ \\ date of birth: _...  \n",
       "1  \\ name: ___ unit no: ___\\ \\ \\ date of birth: _...  \n",
       "2  \\ name: ___ unit no: ___\\ \\ \\ date of birth: _...  \n",
       "3  \\ name: ___ unit no: ___\\ \\ \\ date of birth: _...  \n",
       "4  \\ name: ___ unit no: ___\\ \\ \\ date of birth: _...  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing embeddings: 100%|| 14335/14335 [08:12<00:00, 29.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17294481</td>\n",
       "      <td>\\\\nName:  ___                   Unit No:   __...</td>\n",
       "      <td>\\ name: ___ unit no: ___\\ \\ \\ date of birth: _...</td>\n",
       "      <td>[-0.3994, 0.1586, -0.2698, -0.1289, -0.07196, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18797135</td>\n",
       "      <td>\\\\nName:  ___                 Unit No:   ___\\...</td>\n",
       "      <td>\\ name: ___ unit no: ___\\ \\ \\ date of birth: _...</td>\n",
       "      <td>[0.1487, 0.2366, -0.372, -0.07855, -0.1487, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12318550</td>\n",
       "      <td>\\\\nName:  ___                   Unit No:   __...</td>\n",
       "      <td>\\ name: ___ unit no: ___\\ \\ \\ date of birth: _...</td>\n",
       "      <td>[-0.2405, 0.3093, -0.4531, -0.02596, -0.001131...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13132088</td>\n",
       "      <td>\\\\nName:  ___             Unit No:   ___\\\\n \\...</td>\n",
       "      <td>\\ name: ___ unit no: ___\\ \\ \\ date of birth: _...</td>\n",
       "      <td>[-0.092, 0.4846, -0.297, 0.00444, -0.10333, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14607492</td>\n",
       "      <td>\\\\nName:  ___                     Unit No:   ...</td>\n",
       "      <td>\\ name: ___ unit no: ___\\ \\ \\ date of birth: _...</td>\n",
       "      <td>[-0.5337, 0.2896, -0.2017, 0.002855, -0.03348,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id                                               text  \\\n",
       "0    17294481   \\\\nName:  ___                   Unit No:   __...   \n",
       "1    18797135   \\\\nName:  ___                 Unit No:   ___\\...   \n",
       "2    12318550   \\\\nName:  ___                   Unit No:   __...   \n",
       "3    13132088   \\\\nName:  ___             Unit No:   ___\\\\n \\...   \n",
       "4    14607492   \\\\nName:  ___                     Unit No:   ...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  \\ name: ___ unit no: ___\\ \\ \\ date of birth: _...   \n",
       "1  \\ name: ___ unit no: ___\\ \\ \\ date of birth: _...   \n",
       "2  \\ name: ___ unit no: ___\\ \\ \\ date of birth: _...   \n",
       "3  \\ name: ___ unit no: ___\\ \\ \\ date of birth: _...   \n",
       "4  \\ name: ___ unit no: ___\\ \\ \\ date of birth: _...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-0.3994, 0.1586, -0.2698, -0.1289, -0.07196, ...  \n",
       "1  [0.1487, 0.2366, -0.372, -0.07855, -0.1487, -0...  \n",
       "2  [-0.2405, 0.3093, -0.4531, -0.02596, -0.001131...  \n",
       "3  [-0.092, 0.4846, -0.297, 0.00444, -0.10333, -0...  \n",
       "4  [-0.5337, 0.2896, -0.2017, 0.002855, -0.03348,...  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis_df = process_dataframe(dis_df, 'cleaned_text', max_workers=4)\n",
    "dis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14335 entries, 0 to 14334\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   subject_id    14335 non-null  int64 \n",
      " 1   text          14335 non-null  object\n",
      " 2   cleaned_text  14335 non-null  object\n",
      " 3   embeddings    14335 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 448.1+ KB\n"
     ]
    }
   ],
   "source": [
    "dis_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_df.to_csv('discharge_with_embeddings.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
